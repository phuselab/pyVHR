{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RndCVqh915_g"
   },
   "source": [
    "<a id='setup'></a>\n",
    "#Initial setup \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFP37oIXuKQN"
   },
   "outputs": [],
   "source": [
    "# -- MAIN IMPORT\n",
    "\n",
    "import pyVHR as vhr\n",
    "import numpy as np\n",
    "\n",
    "# Plotting: set 'colab' for Google Colaboratory, 'notebook' otherwise\n",
    "vhr.plot.VisualizeParams.renderer = 'colab'  # or 'notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYKTCUkf7Y6l"
   },
   "outputs": [],
   "source": [
    "# -- LOAD A DATASET\n",
    "\n",
    "dataset_name = 'ubfc1'                   # the name of the python class handling it \n",
    "video_DIR = '/var/datasets/VHR1/UBFC1/'  # dir containing videos\n",
    "BVP_DIR = '/var/datasets/VHR1/UBFC1/'    # dir containing BVPs GT\n",
    "\n",
    "dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)\n",
    "allvideo = dataset.videoFilenames\n",
    "\n",
    "# print the list of video names with the progressive index (idx)\n",
    "for v in range(len(allvideo)):\n",
    "  print(v, allvideo[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKz1w2i48u-Z"
   },
   "outputs": [],
   "source": [
    "# -- PARAMETER SETTING\n",
    "\n",
    "wsize = 6           # seconds of video processed (with overlapping) for each estimate \n",
    "video_idx = 0      # index of the video to be processed\n",
    "fname = dataset.getSigFilename(video_idx)\n",
    "sigGT = dataset.readSigfile(fname)\n",
    "bpmGT, timesGT = sigGT.getBPM(wsize)\n",
    "videoFileName = dataset.getVideoFilename(video_idx)\n",
    "print('Video processed name: ', videoFileName)\n",
    "fps = vhr.extraction.get_fps(videoFileName)\n",
    "print('Video frame rate:     ',fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bv3FNU0kxLI8"
   },
   "outputs": [],
   "source": [
    "# -- DISPLAY VIDEO FRAMES\n",
    "\n",
    "vhr.plot.display_video(videoFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnKKDdQ_ZhGO"
   },
   "source": [
    "# MTTS-CAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd9-878FZc88"
   },
   "source": [
    "**DeepPhys: Video-Based Physiological Measurement Using Convolutional Attention Networks**\n",
    "\n",
    "*Weixuan Chen and Daniel McDuff*\n",
    "\n",
    "**Abstract**. Non-contact video-based physiological measurement has many applications in health care and human-computer interaction. Practical applications require measurements to be accurate even in the presence of large head rotations. We propose the first end-to-end system for video-based measurement of heart and breathing rate using a deep convolutional network. The system features a new motion representation based on a skin reflection model and a new attention mechanism using appearance information to guide motion estimation, both of which enable robust measurement under heterogeneous lighting and major motions. Our approach significantly outperforms all current state-of-the-art methods on both RGB and infrared video datasets. Furthermore, it allows spatial-temporal distributions of physiological signals to be visualized via the attention mechanism.\n",
    "\n",
    "papers: \n",
    "* [DeepPhys: Video-Based Physiological Measurement Using Convolutional Attention Networks](https://web.media.mit.edu/~cvx/docs/18.Chen-etal-ECCV.pdf), \n",
    "* [Multi-Task Temporal Shift Attention Networks for On-Device Contactless Vitals Measurement\n",
    "](https://papers.nips.cc/paper/2020/file/e1228be46de6a0234ac22ded31417bc7-Paper.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2WR2MU6L-y1"
   },
   "outputs": [],
   "source": [
    "# extract raw frames\n",
    "sp = vhr.extraction.sig_processing.SignalProcessing()\n",
    "frames = sp.extract_raw(videoFileName)\n",
    "print('Frames shape:', frames.shape)\n",
    "\n",
    "# apply MTTS_CAN model\n",
    "bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(frames, fps, verb=1)\n",
    "bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n",
    "vhr.plot.visualize_BVPs([bvps.data], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nVCmksezBGq"
   },
   "outputs": [],
   "source": [
    "## -- analysis\n",
    "from pyVHR.utils.errors import getErrors, printErrors, displayErrors, BVP_windowing\n",
    "from pyVHR.extraction.utils import sliding_straded_win_idx\n",
    "\n",
    "# BVP windowing & BPM estimate\n",
    "bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n",
    "bpmES = vhr.BPM.BVP_to_BPM(bvp_win, fps) \n",
    "\n",
    "# compute and print errors\n",
    "RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n",
    "vhr.utils.printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n",
    "displayErrors(bpmES, bpmGT, timesES, timesGT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgMi3OkXdkIq"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcHFHqIj0BQ8"
   },
   "outputs": [],
   "source": [
    "# run on a single video\n",
    "from pyVHR.analysis.pipeline import DeepPipeline\n",
    "\n",
    "filename = '/var/datasets/VHR1/UBFC1/after-exercise/vid.avi'\n",
    "\n",
    "pipe = DeepPipeline()\n",
    "\n",
    "time, BPM = pipe.run_on_video(filename, method='MTTS_CAN')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pyVHR_demo_deep.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
